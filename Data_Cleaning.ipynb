{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# define the path of the csv file \n",
    "file_path = r'C:\\Users\\Maryam\\Desktop\\Job applications\\Portfolio\\DataSets\\Uncleaned_DS_Jobs.csv'\n",
    "\n",
    "# convert the table to a dataframe\n",
    "df = pd.read_csv(file_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this part of the code, a function is developed to classify the positions into the main categories we are intrested in and assign everything else to a categoty called others \n",
    "# in order to filter the data for these position at the end of the file \n",
    "# calssify the positions into the main categories which are: software enginer, data scientist, data analyst, data engineer and machine learning engineer \n",
    "\n",
    "def job_classification(row):\n",
    "    if 'Software Engineer' in row:\n",
    "        return 'Software Engineer'  \n",
    "    elif 'Data' in row and 'Scientist' in row:\n",
    "        return 'Data Scientist'\n",
    "    elif 'Data' in row and 'Analyst' in row:\n",
    "        return 'Data Analyst'\n",
    "    elif 'Data' in row and 'Engineer' in row:\n",
    "        return 'Data Engineer'\n",
    "    elif 'Machine' in row and 'Learning' in row and 'Engineer' in row:\n",
    "        return 'Machine Learning Engineer'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "# apply the function to the Job Title column in the dataframe     \n",
    "df['Job Classification'] = df['Job Title'].apply(job_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level of Experience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function classifies the positions according to the level of experience: Expert, Senior, Mid-level and Junior \n",
    "\n",
    "def exp_level(row):\n",
    "    if  'Lead' in row or 'Experienced' in row or 'Principal' in row:\n",
    "        return 'Expert' \n",
    "    elif 'Sr' in row or 'Senior' in row: \n",
    "        return 'Senior'\n",
    "    elif 'Jr' in row or 'Associate' in row: \n",
    "        return 'Junior'\n",
    "    else: \n",
    "        return 'Mid-level'\n",
    "    \n",
    "df['Experience Level'] = df['Job Title'].apply(exp_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age of the Company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the company age from the year in which it was founded \n",
    "\n",
    "# since some values are missing which is indicated by (-1). The value is replaced by NA so it does not affect the calculation \n",
    "df['Founded'] = df['Founded'].replace(-1, pd.NA)\n",
    "\n",
    "if (df['Founded'] == -1).any():\n",
    "    df['Company Age'] = 'NA'\n",
    "else:\n",
    "    # Calculate 'Company Age' based on 'Founded' column\n",
    "    df['Company Age'] = 2024 - df['Founded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Size Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of the company is based on the number of employees. For some entries it is given as a range (x to y) or more than a specific value (10000). There are also some missing values indicated as (-1)\n",
    "# or unknown\n",
    "\n",
    "# in this part, the missing values, texts and characters are removed.  \n",
    "df['Size'] = df['Size'].str.replace('-1', 'Unknown')\n",
    "df['Size'] = df['Size'].str.replace('employees', '')\n",
    "df['Size'] = df['Size'].str.replace('+', '')\n",
    "\n",
    "# this function split the range into two different columns \n",
    "def split_size(row):\n",
    "    if row.strip() != 'Unknown':\n",
    "        if row.strip() == '10000':\n",
    "            return pd.Series(['10000', '10000'])\n",
    "        else:\n",
    "            return pd.Series(row.split('to'))\n",
    "    else: \n",
    "        return pd.Series(['Unknown', 'Unknown'])\n",
    "    \n",
    "df[['Min Size', 'Max Size']] = df['Size'].apply(split_size)\n",
    "\n",
    "# once the columns are only numbers, the average size of the company is calcluated according to the function below \n",
    "def avg_size(row):\n",
    "    row_1 = row['Min Size']\n",
    "    row_2 = row['Max Size']\n",
    "    if row_1 != 'Unknown' and row_2 != 'Unknown':\n",
    "       row_1 = pd.to_numeric(row_1, errors='coerce')\n",
    "       row_2 = pd.to_numeric(row_2, errors='coerce')\n",
    "       average = ( row_1 +  row_2)/2\n",
    "       average = int(average)\n",
    "       return average\n",
    "    else :\n",
    "      return 'Unknown'\n",
    "\n",
    "df['Avg Size'] = df.apply(avg_size, axis=1)\n",
    "\n",
    "# the companies are classified into three categories according to the number of employees \n",
    "def size_classification(row):\n",
    "    if  row == 'Unknown':\n",
    "        return 'Unknown'\n",
    "    elif int(row) >= 10000:\n",
    "        return 'Large'\n",
    "    elif int (row) < 100:\n",
    "        return 'Small'\n",
    "    else :\n",
    "        return 'Medium'\n",
    "    \n",
    "df['Size Classification'] = df['Avg Size'].apply(size_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Salary Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the salaries are given as a rang for each entry so we need to split them first to find the average\n",
    "# all texts and characters are removed first and then the range of the salary is divided into two columns\n",
    "        \n",
    "df['Salary Estimate'] = df['Salary Estimate'].str.replace('$','')\n",
    "df['Salary Estimate'] = df['Salary Estimate'].str.replace('K','')\n",
    "df['Salary Estimate'] = df['Salary Estimate'].str.replace('(Glassdoor est.)','')\n",
    "df['Salary Estimate'] = df['Salary Estimate'].str.replace('(Employer est.)','')\n",
    "df[['Min Salary', 'Max Salary']] = df['Salary Estimate'].str.split('-', expand=True)\n",
    "\n",
    "# convert the new columns into numberic values in order to calculate the average \n",
    "df['Min Salary'] = pd.to_numeric(df['Min Salary'])\n",
    "df['Max Salary'] = pd.to_numeric(df['Max Salary'])\n",
    "\n",
    "# calculate the average and convert it to integer\n",
    "df['Avg Salary'] = (df['Max Salary'] + df['Min Salary'])/2\n",
    "df['Avg Salary'] = df['Avg Salary'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Technical Skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of the technical requirments are given within the job description column. In this part, we are creating a new column for each of the skills we are interested in and then assign a value of 1 or 0\n",
    "# if they are mentioned within this column or not \n",
    "\n",
    "# Determine the skill set required for all positions \n",
    "skills = ['Python', 'aws', 'Matplotlib', 'Scikit-Learn', 'TensorFlow', 'PyTorch', 'SQL',  'Hadoop', 'Spark', 'Docker', 'Azure', 'Git', 'NLTK', ' spaCy', 'Java', 'Apache Airflow', 'Tableau', 'Power BI',\n",
    "          'Web Scraping', 'APIs', 'Apache Kafka']\n",
    "\n",
    "for skill in skills:\n",
    "    df[skill] = 0  # Set the initial value to 0\n",
    "    if (df['Job Description'].str.contains(skill, case=False)).any():\n",
    "        df.loc[df['Job Description'].str.contains(skill, case=False), skill] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filtration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the data has been cleaned, we will extract the entried related to the positions below and save them to another file\n",
    "\n",
    "# here are the positions that will be included for the next step \n",
    "selected_classification = ['Data Scientist', 'Data Analyst', 'Machine Learning Engineer', 'Data Engineer', 'Software Engineer']\n",
    "\n",
    "# select the entries to be extracted from the old dataframe\n",
    "filtered_df = df[df['Job Classification'].isin(selected_classification)]\n",
    "\n",
    "# define the location in which the new data will be saved   \n",
    "new_file_path = r'C:\\Users\\Maryam\\Desktop\\Job applications\\Portfolio\\DataSets\\Cleaned_Tech_Jobs_Data.csv'\n",
    "\n",
    "# write the filtered dataframe to a csv file\n",
    "filtered_df.to_csv(new_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
